{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([54866, 7]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        episode: Tensor(shape=torch.Size([54866]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        image: Tensor(shape=torch.Size([54866, 84, 84, 3]), device=cpu, dtype=torch.uint8, is_shared=False),\n",
      "        obs: Tensor(shape=torch.Size([54866, 32]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "saving to /scr/shared/datasets/robot_pref/stack_panda/stack_panda.pt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert from robomimic hdf5 to tensordict format\n",
    "\"\"\"\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "from tensordict import TensorDict\n",
    "import numpy as np\n",
    "\n",
    "save_dataset = True\n",
    "data_path = \"/scr/shared/datasets/robot_pref/stack_panda/stack_panda.hdf5\"\n",
    "\n",
    "with h5py.File(data_path, 'r') as f:\n",
    "    data = f[\"data\"]\n",
    "    \n",
    "    total_len = 0\n",
    "    actions = []\n",
    "    episodes = []\n",
    "    images = []\n",
    "    obs = []\n",
    "    rewards = []\n",
    "    \n",
    "    for demo in sorted(data.keys(), key=lambda x: int(x.split('_')[1])):\n",
    "            \n",
    "        demo_data = data[demo]\n",
    "        demo_len = len(demo_data[\"actions\"])\n",
    "        \n",
    "        actions.append(demo_data[\"actions\"][:])\n",
    "        episodes.append(torch.full((demo_len,), int(demo.split('_')[1])))\n",
    "        images.append(demo_data[\"obs\"][\"agentview_image\"][:])\n",
    "\n",
    "        # observation consists of these\n",
    "        # [\"robot0_eef_pos\", \"robot0_eef_quat\", \"robot0_gripper_qpos\", \"object\"]\n",
    "        obs.append(np.concatenate([\n",
    "            demo_data[\"obs\"][\"robot0_eef_pos\"][:],\n",
    "            demo_data[\"obs\"][\"robot0_eef_quat\"][:], \n",
    "            demo_data[\"obs\"][\"robot0_gripper_qpos\"][:],\n",
    "            demo_data[\"obs\"][\"object\"][:] # obs varies by task\n",
    "        ], axis=1))\n",
    "\n",
    "        # rewards.append(demo_data[\"rewards\"][:])\n",
    "        \n",
    "        total_len += demo_len\n",
    "    \n",
    "    # Convert numpy arrays to tensors and concatenate all data\n",
    "    tensordict = TensorDict({\n",
    "        \"action\": torch.cat([torch.from_numpy(a).float() for a in actions]),\n",
    "        \"episode\": torch.cat(episodes),\n",
    "        \"image\": torch.cat([torch.from_numpy(img) for img in images]), \n",
    "        \"obs\": torch.cat([torch.from_numpy(o).float() for o in obs]),\n",
    "        # \"reward\": torch.cat([torch.from_numpy(r).float() for r in rewards])\n",
    "    }, batch_size=torch.Size([]))\n",
    "    \n",
    "    print(tensordict)\n",
    "\n",
    "    if save_dataset:\n",
    "        # save to data path but as a .pt instead of .hdf5\n",
    "        # Convert .hdf5 extension to .pt\n",
    "        save_path = str(data_path).replace('.hdf5', '.pt')\n",
    "        print(f\"saving to {save_path}\")\n",
    "        torch.save(tensordict, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== /scr/shared/datasets/robot_pref/lift_panda/lift_panda.hdf5 ====\n",
      "actions:\n",
      "  shape: (68148, 7)\n",
      "  mean: [ 0.03534264  0.00816505 -0.03161107 -0.00074413  0.00165334 -0.00505467\n",
      " -0.65613077]\n",
      "  min: [-1. -1. -1. -1. -1. -1. -1.]\n",
      "  max: [1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "==== /scr/shared/datasets/robot_pref/lift_sawyer/lift_sawyer.hdf5 ====\n",
      "actions:\n",
      "  shape: (66282, 7)\n",
      "  mean: [ 0.0294056  -0.04304439 -0.04729058  0.00527456 -0.00422478 -0.01669778\n",
      " -0.65001056]\n",
      "  min: [-1.         -1.         -1.         -0.44683041 -1.         -1.\n",
      " -1.        ]\n",
      "  max: [1.         1.         1.         1.         0.35533006 1.\n",
      " 1.        ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def print_stats(arr, name):\n",
    "    arr = np.array(arr)\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  shape: {arr.shape}\")\n",
    "    print(f\"  mean: {np.mean(arr, axis=0)}\")\n",
    "    print(f\"  min: {np.min(arr, axis=0)}\")\n",
    "    print(f\"  max: {np.max(arr, axis=0)}\")\n",
    "    print()\n",
    "\n",
    "path = \"/scr/shared/datasets/robot_pref/lift_panda/lift_panda.hdf5\"\n",
    "sawyer_path = \"/scr/shared/datasets/robot_pref/lift_sawyer/lift_sawyer.hdf5\"\n",
    "\n",
    "for p in [path, sawyer_path]:\n",
    "    print(f\"==== {p} ====\")\n",
    "    with h5py.File(p, 'r') as f:\n",
    "        data = f[\"data\"]\n",
    "        all_actions = []\n",
    "        for key in data.keys():\n",
    "            actions = data[key][\"actions\"][:]\n",
    "            all_actions.append(actions)\n",
    "        if all_actions:\n",
    "            all_actions = np.concatenate(all_actions, axis=0)\n",
    "            print_stats(all_actions, \"actions\")\n",
    "        else:\n",
    "            print(\"No demos found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['actions', 'datagen_info', 'obs', 'src_demo_inds', 'src_demo_labels', 'states']> existing demos\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"/scr/shared/datasets/robot_pref/lift_panda/lift_panda.hdf5\"\n",
    "other_data_path = \"/tmp/medium_random/lift/demo_src_lift_task_Lift_r_Panda/demo_failed.hdf5\"\n",
    "combined_path = \"/tmp/combined/lift/demo_src_lift_task_Lift_r_Panda/demo_failed.hdf5\"\n",
    "\n",
    "# Open the destination file in append mode\n",
    "with h5py.File(data_path, 'a') as f, h5py.File(other_data_path, 'r') as f2:\n",
    "    data = f[\"data\"]\n",
    "    data2 = f2[\"data\"]\n",
    "\n",
    "    print((data[\"demo_1\"].keys()), \"existing demos\")\n",
    "\n",
    "    # # Get current max index in data\n",
    "    # existing_keys = list(data.keys())\n",
    "    # max_index = max(int(k.split('_')[-1]) for k in existing_keys)\n",
    "\n",
    "    # for k in data2.keys():\n",
    "    #     # Compute new index\n",
    "    #     new_index = max_index + 1\n",
    "    #     new_key = f\"demo_{new_index}\"\n",
    "        \n",
    "    #     # Copy group or dataset\n",
    "    #     f.copy(data2[k], data, name=new_key)\n",
    "\n",
    "    #     # Increment for next copy\n",
    "    #     max_index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pref",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
