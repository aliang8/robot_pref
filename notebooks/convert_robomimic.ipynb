{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([54866, 7]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        episode: Tensor(shape=torch.Size([54866]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        image: Tensor(shape=torch.Size([54866, 84, 84, 3]), device=cpu, dtype=torch.uint8, is_shared=False),\n",
      "        obs: Tensor(shape=torch.Size([54866, 32]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "saving to /scr/shared/datasets/robot_pref/stack_panda/stack_panda.pt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert from robomimic hdf5 to tensordict format\n",
    "\"\"\"\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "from tensordict import TensorDict\n",
    "import numpy as np\n",
    "\n",
    "save_dataset = True\n",
    "data_path = \"/scr/shared/datasets/robot_pref/stack_panda/stack_panda.hdf5\"\n",
    "\n",
    "with h5py.File(data_path, 'r') as f:\n",
    "    data = f[\"data\"]\n",
    "    \n",
    "    total_len = 0\n",
    "    actions = []\n",
    "    episodes = []\n",
    "    images = []\n",
    "    obs = []\n",
    "    rewards = []\n",
    "    \n",
    "    for demo in sorted(data.keys(), key=lambda x: int(x.split('_')[1])):\n",
    "            \n",
    "        demo_data = data[demo]\n",
    "        demo_len = len(demo_data[\"actions\"])\n",
    "        \n",
    "        actions.append(demo_data[\"actions\"][:])\n",
    "        episodes.append(torch.full((demo_len,), int(demo.split('_')[1])))\n",
    "        images.append(demo_data[\"obs\"][\"agentview_image\"][:])\n",
    "\n",
    "        # observation consists of these\n",
    "        # [\"robot0_eef_pos\", \"robot0_eef_quat\", \"robot0_gripper_qpos\", \"object\"]\n",
    "        obs.append(np.concatenate([\n",
    "            demo_data[\"obs\"][\"robot0_eef_pos\"][:],\n",
    "            demo_data[\"obs\"][\"robot0_eef_quat\"][:], \n",
    "            demo_data[\"obs\"][\"robot0_gripper_qpos\"][:],\n",
    "            demo_data[\"obs\"][\"object\"][:] # obs varies by task\n",
    "        ], axis=1))\n",
    "\n",
    "        # rewards.append(demo_data[\"rewards\"][:])\n",
    "        \n",
    "        total_len += demo_len\n",
    "    \n",
    "    # Convert numpy arrays to tensors and concatenate all data\n",
    "    tensordict = TensorDict({\n",
    "        \"action\": torch.cat([torch.from_numpy(a).float() for a in actions]),\n",
    "        \"episode\": torch.cat(episodes),\n",
    "        \"image\": torch.cat([torch.from_numpy(img) for img in images]), \n",
    "        \"obs\": torch.cat([torch.from_numpy(o).float() for o in obs]),\n",
    "        # \"reward\": torch.cat([torch.from_numpy(r).float() for r in rewards])\n",
    "    }, batch_size=torch.Size([]))\n",
    "    \n",
    "    print(tensordict)\n",
    "\n",
    "    if save_dataset:\n",
    "        # save to data path but as a .pt instead of .hdf5\n",
    "        # Convert .hdf5 extension to .pt\n",
    "        save_path = str(data_path).replace('.hdf5', '.pt')\n",
    "        print(f\"saving to {save_path}\")\n",
    "        torch.save(tensordict, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== /scr/shared/datasets/robot_pref/lift_panda/lift_panda.hdf5 ====\n",
      "actions:\n",
      "  shape: (68148, 7)\n",
      "  mean: [ 0.03534264  0.00816505 -0.03161107 -0.00074413  0.00165334 -0.00505467\n",
      " -0.65613077]\n",
      "  min: [-1. -1. -1. -1. -1. -1. -1.]\n",
      "  max: [1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "==== /scr/shared/datasets/robot_pref/lift_sawyer/lift_sawyer.hdf5 ====\n",
      "actions:\n",
      "  shape: (66282, 7)\n",
      "  mean: [ 0.0294056  -0.04304439 -0.04729058  0.00527456 -0.00422478 -0.01669778\n",
      " -0.65001056]\n",
      "  min: [-1.         -1.         -1.         -0.44683041 -1.         -1.\n",
      " -1.        ]\n",
      "  max: [1.         1.         1.         1.         0.35533006 1.\n",
      " 1.        ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def print_stats(arr, name):\n",
    "    arr = np.array(arr)\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  shape: {arr.shape}\")\n",
    "    print(f\"  mean: {np.mean(arr, axis=0)}\")\n",
    "    print(f\"  min: {np.min(arr, axis=0)}\")\n",
    "    print(f\"  max: {np.max(arr, axis=0)}\")\n",
    "    print()\n",
    "\n",
    "path = \"/scr/shared/datasets/robot_pref/lift_panda/lift_panda.hdf5\"\n",
    "sawyer_path = \"/scr/shared/datasets/robot_pref/lift_sawyer/lift_sawyer.hdf5\"\n",
    "\n",
    "for p in [path, sawyer_path]:\n",
    "    print(f\"==== {p} ====\")\n",
    "    with h5py.File(p, 'r') as f:\n",
    "        data = f[\"data\"]\n",
    "        all_actions = []\n",
    "        for key in data.keys():\n",
    "            actions = data[key][\"actions\"][:]\n",
    "            all_actions.append(actions)\n",
    "        if all_actions:\n",
    "            all_actions = np.concatenate(all_actions, axis=0)\n",
    "            print_stats(all_actions, \"actions\")\n",
    "        else:\n",
    "            print(\"No demos found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"env_name\": \"Lift\",\n",
      "    \"env_version\": \"1.4.1\",\n",
      "    \"type\": 1,\n",
      "    \"env_kwargs\": {\n",
      "        \"robots\": [\n",
      "            \"Panda\"\n",
      "        ],\n",
      "        \"controller_configs\": {\n",
      "            \"type\": \"OSC_POSE\",\n",
      "            \"input_max\": 1,\n",
      "            \"input_min\": -1,\n",
      "            \"output_max\": [\n",
      "                0.05,\n",
      "                0.05,\n",
      "                0.05,\n",
      "                0.5,\n",
      "                0.5,\n",
      "                0.5\n",
      "            ],\n",
      "            \"output_min\": [\n",
      "                -0.05,\n",
      "                -0.05,\n",
      "                -0.05,\n",
      "                -0.5,\n",
      "                -0.5,\n",
      "                -0.5\n",
      "            ],\n",
      "            \"kp\": 150,\n",
      "            \"damping_ratio\": 1,\n",
      "            \"impedance_mode\": \"fixed\",\n",
      "            \"kp_limits\": [\n",
      "                0,\n",
      "                300\n",
      "            ],\n",
      "            \"damping_ratio_limits\": [\n",
      "                0,\n",
      "                10\n",
      "            ],\n",
      "            \"position_limits\": null,\n",
      "            \"orientation_limits\": null,\n",
      "            \"uncouple_pos_ori\": true,\n",
      "            \"control_delta\": true,\n",
      "            \"interpolation\": null,\n",
      "            \"ramp_ratio\": 0.2\n",
      "        },\n",
      "        \"reward_shaping\": false,\n",
      "        \"camera_names\": [\n",
      "            \"agentview\",\n",
      "            \"robot0_eye_in_hand\"\n",
      "        ],\n",
      "        \"camera_heights\": 84,\n",
      "        \"camera_widths\": 84,\n",
      "        \"has_renderer\": false,\n",
      "        \"has_offscreen_renderer\": true,\n",
      "        \"ignore_done\": true,\n",
      "        \"use_object_obs\": true,\n",
      "        \"use_camera_obs\": true,\n",
      "        \"camera_depths\": false,\n",
      "        \"render_gpu_device_id\": 0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"/scr/shared/datasets/robot_pref/lift_panda/lift_panda.hdf5\"\n",
    "other_data_path = \"/tmp/medium_random/lift/demo_src_lift_task_Lift_r_Panda/demo_failed.hdf5\"\n",
    "combined_path = \"/tmp/combined/lift/demo_src_lift_task_Lift_r_Panda/demo_failed.hdf5\"\n",
    "\n",
    "# Open the destination file in append mode\n",
    "with h5py.File(data_path, 'a') as f, h5py.File(other_data_path, 'r') as f2:\n",
    "    data = f[\"data\"]\n",
    "    data2 = f2[\"data\"]\n",
    "\n",
    "    print((data.attrs[\"env_args\"]))\n",
    "\n",
    "    # # Get current max index in data\n",
    "    # existing_keys = list(data.keys())\n",
    "    # max_index = max(int(k.split('_')[-1]) for k in existing_keys)\n",
    "\n",
    "    # for k in data2.keys():\n",
    "    #     # Compute new index\n",
    "    #     new_index = max_index + 1\n",
    "    #     new_key = f\"demo_{new_index}\"\n",
    "        \n",
    "    #     # Copy group or dataset\n",
    "    #     f.copy(data2[k], data, name=new_key)\n",
    "\n",
    "    #     # Increment for next copy\n",
    "    #     max_index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 demos\n",
      "demo_0: sum of rewards = 35.8387\n",
      "demo_1: sum of rewards = 44.2258\n",
      "demo_10: sum of rewards = 39.9837\n",
      "demo_100: sum of rewards = 3.8742\n",
      "demo_101: sum of rewards = 4.8011\n",
      "demo_102: sum of rewards = 1.2718\n",
      "demo_103: sum of rewards = 0.7761\n",
      "demo_104: sum of rewards = 2.6300\n",
      "demo_105: sum of rewards = 2.8697\n",
      "demo_106: sum of rewards = 3.9472\n",
      "demo_107: sum of rewards = 3.8288\n",
      "demo_108: sum of rewards = 2.5223\n",
      "demo_109: sum of rewards = 47.8541\n",
      "demo_11: sum of rewards = 39.7536\n",
      "demo_110: sum of rewards = 28.6293\n",
      "demo_111: sum of rewards = 1.2053\n",
      "demo_112: sum of rewards = 3.2329\n",
      "demo_113: sum of rewards = 24.0211\n",
      "demo_114: sum of rewards = 3.9564\n",
      "demo_115: sum of rewards = 0.8471\n",
      "demo_116: sum of rewards = 3.5390\n",
      "demo_117: sum of rewards = 1.4920\n",
      "demo_118: sum of rewards = 2.6944\n",
      "demo_119: sum of rewards = 2.2766\n",
      "demo_12: sum of rewards = 43.7404\n",
      "demo_120: sum of rewards = 2.6287\n",
      "demo_121: sum of rewards = 0.2845\n",
      "demo_122: sum of rewards = 4.1312\n",
      "demo_123: sum of rewards = 0.3117\n",
      "demo_124: sum of rewards = 2.7794\n",
      "demo_125: sum of rewards = 2.0052\n",
      "demo_126: sum of rewards = 3.5010\n",
      "demo_127: sum of rewards = 1.0826\n",
      "demo_128: sum of rewards = 1.5563\n",
      "demo_129: sum of rewards = 3.1476\n",
      "demo_13: sum of rewards = 45.5381\n",
      "demo_130: sum of rewards = 3.3156\n",
      "demo_131: sum of rewards = 1.4690\n",
      "demo_132: sum of rewards = 2.6329\n",
      "demo_133: sum of rewards = 0.6679\n",
      "demo_134: sum of rewards = 1.9590\n",
      "demo_135: sum of rewards = 0.8672\n",
      "demo_136: sum of rewards = 3.4168\n",
      "demo_137: sum of rewards = 2.1441\n",
      "demo_138: sum of rewards = 30.2499\n",
      "demo_139: sum of rewards = 2.2299\n",
      "demo_14: sum of rewards = 41.1770\n",
      "demo_140: sum of rewards = 3.1747\n",
      "demo_141: sum of rewards = 0.3480\n",
      "demo_142: sum of rewards = 2.6490\n",
      "demo_143: sum of rewards = 1.8840\n",
      "demo_144: sum of rewards = 1.9602\n",
      "demo_145: sum of rewards = 1.8007\n",
      "demo_146: sum of rewards = 3.0039\n",
      "demo_147: sum of rewards = 2.3045\n",
      "demo_148: sum of rewards = 3.4940\n",
      "demo_149: sum of rewards = 0.7388\n",
      "demo_15: sum of rewards = 39.2876\n",
      "demo_150: sum of rewards = 2.4230\n",
      "demo_151: sum of rewards = 2.1297\n",
      "demo_152: sum of rewards = 3.2156\n",
      "demo_153: sum of rewards = 0.8929\n",
      "demo_154: sum of rewards = 3.6006\n",
      "demo_155: sum of rewards = 4.2294\n",
      "demo_156: sum of rewards = 1.4675\n",
      "demo_157: sum of rewards = 1.4797\n",
      "demo_158: sum of rewards = 1.6145\n",
      "demo_159: sum of rewards = 2.4301\n",
      "demo_16: sum of rewards = 30.0879\n",
      "demo_160: sum of rewards = 2.6477\n",
      "demo_161: sum of rewards = 1.1023\n",
      "demo_162: sum of rewards = 3.6951\n",
      "demo_163: sum of rewards = 2.5084\n",
      "demo_164: sum of rewards = 5.2392\n",
      "demo_165: sum of rewards = 3.2781\n",
      "demo_166: sum of rewards = 2.8579\n",
      "demo_167: sum of rewards = 2.4314\n",
      "demo_168: sum of rewards = 5.1457\n",
      "demo_169: sum of rewards = 2.6904\n",
      "demo_17: sum of rewards = 51.0085\n",
      "demo_170: sum of rewards = 3.8000\n",
      "demo_171: sum of rewards = 3.2974\n",
      "demo_172: sum of rewards = 3.3640\n",
      "demo_173: sum of rewards = 1.8423\n",
      "demo_174: sum of rewards = 2.7965\n",
      "demo_175: sum of rewards = 4.1416\n",
      "demo_176: sum of rewards = 1.8371\n",
      "demo_177: sum of rewards = 1.2579\n",
      "demo_178: sum of rewards = 2.6191\n",
      "demo_179: sum of rewards = 1.3252\n",
      "demo_18: sum of rewards = 29.8770\n",
      "demo_180: sum of rewards = 3.1807\n",
      "demo_181: sum of rewards = 4.0390\n",
      "demo_182: sum of rewards = 4.0880\n",
      "demo_183: sum of rewards = 3.5797\n",
      "demo_184: sum of rewards = 1.4729\n",
      "demo_185: sum of rewards = 3.2414\n",
      "demo_186: sum of rewards = 2.2130\n",
      "demo_187: sum of rewards = 2.6503\n",
      "demo_188: sum of rewards = 1.9894\n",
      "demo_189: sum of rewards = 1.6937\n",
      "demo_19: sum of rewards = 36.6757\n",
      "demo_190: sum of rewards = 1.9175\n",
      "demo_191: sum of rewards = 2.4985\n",
      "demo_192: sum of rewards = 2.2595\n",
      "demo_193: sum of rewards = 2.0397\n",
      "demo_194: sum of rewards = 2.5280\n",
      "demo_195: sum of rewards = 0.8477\n",
      "demo_196: sum of rewards = 1.3230\n",
      "demo_197: sum of rewards = 2.0864\n",
      "demo_198: sum of rewards = 1.7129\n",
      "demo_199: sum of rewards = 2.8678\n",
      "demo_2: sum of rewards = 39.8637\n",
      "demo_20: sum of rewards = 27.1440\n",
      "demo_21: sum of rewards = 47.4595\n",
      "demo_22: sum of rewards = 43.7601\n",
      "demo_23: sum of rewards = 48.8984\n",
      "demo_24: sum of rewards = 34.1550\n",
      "demo_25: sum of rewards = 50.7025\n",
      "demo_26: sum of rewards = 39.3510\n",
      "demo_27: sum of rewards = 43.2627\n",
      "demo_28: sum of rewards = 38.9811\n",
      "demo_29: sum of rewards = 33.3524\n",
      "demo_3: sum of rewards = 28.8605\n",
      "demo_30: sum of rewards = 46.0882\n",
      "demo_31: sum of rewards = 40.6747\n",
      "demo_32: sum of rewards = 33.1687\n",
      "demo_33: sum of rewards = 44.0649\n",
      "demo_34: sum of rewards = 47.1603\n",
      "demo_35: sum of rewards = 33.6589\n",
      "demo_36: sum of rewards = 36.1629\n",
      "demo_37: sum of rewards = 37.8768\n",
      "demo_38: sum of rewards = 27.8394\n",
      "demo_39: sum of rewards = 43.6742\n",
      "demo_4: sum of rewards = 42.1438\n",
      "demo_40: sum of rewards = 29.8997\n",
      "demo_41: sum of rewards = 36.4162\n",
      "demo_42: sum of rewards = 29.1529\n",
      "demo_43: sum of rewards = 31.9289\n",
      "demo_44: sum of rewards = 44.8316\n",
      "demo_45: sum of rewards = 38.5913\n",
      "demo_46: sum of rewards = 45.5923\n",
      "demo_47: sum of rewards = 43.1678\n",
      "demo_48: sum of rewards = 45.9628\n",
      "demo_49: sum of rewards = 32.0387\n",
      "demo_5: sum of rewards = 33.5786\n",
      "demo_50: sum of rewards = 46.8760\n",
      "demo_51: sum of rewards = 33.2761\n",
      "demo_52: sum of rewards = 28.9561\n",
      "demo_53: sum of rewards = 49.1336\n",
      "demo_54: sum of rewards = 37.8775\n",
      "demo_55: sum of rewards = 27.9438\n",
      "demo_56: sum of rewards = 31.6167\n",
      "demo_57: sum of rewards = 39.3731\n",
      "demo_58: sum of rewards = 32.9723\n",
      "demo_59: sum of rewards = 40.9204\n",
      "demo_6: sum of rewards = 50.7917\n",
      "demo_60: sum of rewards = 41.7633\n",
      "demo_61: sum of rewards = 29.9423\n",
      "demo_62: sum of rewards = 52.8544\n",
      "demo_63: sum of rewards = 44.8956\n",
      "demo_64: sum of rewards = 37.2624\n",
      "demo_65: sum of rewards = 44.7963\n",
      "demo_66: sum of rewards = 42.1257\n",
      "demo_67: sum of rewards = 31.5623\n",
      "demo_68: sum of rewards = 36.6132\n",
      "demo_69: sum of rewards = 40.8912\n",
      "demo_7: sum of rewards = 49.0758\n",
      "demo_70: sum of rewards = 40.7101\n",
      "demo_71: sum of rewards = 39.4232\n",
      "demo_72: sum of rewards = 45.2121\n",
      "demo_73: sum of rewards = 38.6672\n",
      "demo_74: sum of rewards = 41.2425\n",
      "demo_75: sum of rewards = 45.6997\n",
      "demo_76: sum of rewards = 30.0744\n",
      "demo_77: sum of rewards = 38.4511\n",
      "demo_78: sum of rewards = 41.7753\n",
      "demo_79: sum of rewards = 37.7970\n",
      "demo_8: sum of rewards = 32.8630\n",
      "demo_80: sum of rewards = 35.0602\n",
      "demo_81: sum of rewards = 34.2394\n",
      "demo_82: sum of rewards = 35.6871\n",
      "demo_83: sum of rewards = 45.3245\n",
      "demo_84: sum of rewards = 37.4576\n",
      "demo_85: sum of rewards = 36.7787\n",
      "demo_86: sum of rewards = 41.0947\n",
      "demo_87: sum of rewards = 46.7515\n",
      "demo_88: sum of rewards = 30.4256\n",
      "demo_89: sum of rewards = 34.6870\n",
      "demo_9: sum of rewards = 45.6327\n",
      "demo_90: sum of rewards = 43.3093\n",
      "demo_91: sum of rewards = 34.8355\n",
      "demo_92: sum of rewards = 38.2504\n",
      "demo_93: sum of rewards = 39.9183\n",
      "demo_94: sum of rewards = 6.4883\n",
      "demo_95: sum of rewards = 4.3457\n",
      "demo_96: sum of rewards = 5.3551\n",
      "demo_97: sum of rewards = 4.1184\n",
      "demo_98: sum of rewards = 6.3152\n",
      "demo_99: sum of rewards = 31.9222\n",
      "\n",
      "Summary:\n",
      "Average sum of rewards across all demos: 20.5284\n",
      "Standard deviation: 18.6883\n",
      "Min reward sum: 0.2845\n",
      "Max reward sum: 52.8544\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"/tmp/mimicgen_stack_100/stack/demo_src_stack_task_D0_r_Panda/demo_aug.hdf5\"\n",
    "\n",
    "# Dictionary to store results\n",
    "demo_reward_sums = {}\n",
    "\n",
    "with h5py.File(data_path, 'r') as f:\n",
    "    # Get all demo keys\n",
    "    demo_keys = list(f[\"data\"].keys())\n",
    "    print(f\"Found {len(demo_keys)} demos\")\n",
    "    \n",
    "    for demo_key in demo_keys:\n",
    "        # Access the rewards for this demo\n",
    "        rewards = f[\"data\"][demo_key][\"rewards\"][:]\n",
    "        \n",
    "        # Compute sum of rewards for this demo\n",
    "        reward_sum = np.sum(rewards)\n",
    "        demo_reward_sums[demo_key] = reward_sum\n",
    "        \n",
    "        print(f\"{demo_key}: sum of rewards = {reward_sum:.4f}\")\n",
    "\n",
    "# Compute overall statistics\n",
    "all_reward_sums = list(demo_reward_sums.values())\n",
    "average_reward_sum = np.mean(all_reward_sums)\n",
    "std_reward_sum = np.std(all_reward_sums)\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Average sum of rewards across all demos: {average_reward_sum:.4f}\")\n",
    "print(f\"Standard deviation: {std_reward_sum:.4f}\")\n",
    "print(f\"Min reward sum: {np.min(all_reward_sums):.4f}\")\n",
    "print(f\"Max reward sum: {np.max(all_reward_sums):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pref",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
